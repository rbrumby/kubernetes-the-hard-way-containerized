# Setting up kubelet TLS bootstrapping
In the kubelets systemd unit file the ExecStart included references to --bootstrap-kubeconfig & --kubeconfig. Neither of these files exist yet & the kubelet refused to start because of the missing bootstrap kubeconfig file.
Following the steps described [here](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-tls-bootstrapping/), we create a bootstrap token in the kube-system namespace following a specific naming pattern and containing a token-id & token-secret which make up the token we put in the kubelets kubeconfig. The token-id must be 6 characters long & the token secret must be 16 characters long. They can both only contain lower-case letters & numbers. The token id & secret combined must match regular expression **[a-z0-9]{6}.[a-z0-9]{16}**. I haven't found much advice on how these are expected to be generated or why they are so restrictive. If I do, I will update this page.

## Create the kubelet bootstrap kubeconfig file
```
. /etc/kubernetes/env.sh

sudo kubectl config set-cluster k8sc01 \
  --certificate-authority=/etc/kubernetes/pki/ca.crt \
  --embed-certs=false \
  --server=https://${MASTER_LB}:6443 \
  --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf

sudo kubectl config set-credentials bootstrap-kubelet \
  --token=${BOOTSTRAP_TOKEN_ID}.${BOOTSTRAP_SECRET} \
  --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf

sudo kubectl config set-context default \
  --cluster=k8sc01 \
  --user=bootstrap-kubelet \
  --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf

sudo kubectl config use-context default \
  --kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf
```
### What just happened?
- We created the bootstrap-kubelet.conf file that we previously configured the kubelet with (in its systemd unit file).

## Start the kubelet (
If systemd is still trying to restart it, you don't need this step!
```
sudo systemctl start kubelet
```
### What just happened?
- We started the kubelet which should now be running but if this is the first control plane node there will be lots of complaints about not being able to access the API Server (because we haven't set it up yet):
```
journalctl -u kubelet -f
```
- If this is a subsequent control plane node or a worker node & the master VIP is assigned to a master node with a running API Server, you should find that this node has now made a certificate signing request, had that CSR approved & issued by the controller manager, created its kubelet.conf file referencing the new certificate, authenticated using that certificate & joined the cluster.
