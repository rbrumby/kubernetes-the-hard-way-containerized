# Starting the API server
Now that we have a running (but possibly incomplete) etcd cluster, we can start the API Server.

##Create the API server yaml in the manifests directory
```
cat <<EOF | sudo tee /etc/kubernetes/manifests/kube-apiserver.yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: ${CURRENT_NODE}:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --bind-address=0.0.0.0
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://${CURRENT_NODE}:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --requestheader-client-ca-file=/etc/kubernetes/pki/ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.crt
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    - --encryption-provider-config=/etc/kubernetes/pki/encryption-config.yaml
    - --service-cluster-ip-range=${SERVICE_CIDR}
    image: k8s.gcr.io/kube-apiserver:v1.20.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: ${CURRENT_NODE}
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-apiserver
    readinessProbe:
      failureThreshold: 3
      httpGet:
        host: ${CURRENT_NODE}
        path: /readyz
        port: 6443
        scheme: HTTPS
      periodSeconds: 1
      timeoutSeconds: 15
    resources:
      requests:
        cpu: 250m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: ${CURRENT_NODE}
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priorityClassName: system-node-critical
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
EOF
```
### What just happened?
- We created the API Server manifest in the kubelets static pod manifest directory. The kubelet will spot this & attempt to start a container running the API server.
- We told the API Server to listen (on the default port 6443) on all network addresses & to advertise its address on the VIP/load balancer address (.50) as it doesn't matter which master node a client connects to (because API's are stateless).
- We mounted the pki directory so the API server can access the certificates we created earlier along with standard linux directories containing know CA certificates so the API can validate external server certificates if needed (probably not necessary in our environment but may be later if we get into more advanced topics). We also told the API Server to use the encryption config we created in the previous step.
- If the API Server is running, we can try using kubectl with our admin kubeconfig file:
```
kubectl get pods -A
```
If this is the first node, you'll notice there is little or nothing in the cluster yet - there aren't even any nodes.
- If not, take a look at the logs using:
```
sudo crictl ps -a
sudo crictl logs <find-the-container-id-from-previous-command>
```
If all is going well, you will see some errors about authentication & invalid bearer tokens. That is the kubelet trying to register with the API server which ew haven't finished setting up.

- You should also now see in the kubelet logs (using journalctl) that you are no longer getting connection refused errors.
```
journalctl -u kubelet --since "10 minutes ago"
```
- Instead you should see errors saying that the kubelet cannot register itself because it doesn't have the necessary RBAC permissions.
